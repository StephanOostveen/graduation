\section{Discussion}
\label{sec:discussion}
Traditional automotive benchmarks focused on the describing the network traffic in terms of messages transmitted between physical nodes. While interesting these benchmarks do not explain the reason behind the network traffic requirements. A network and its traffic are an implementation detail required to make the control application in a decentralized architecture work. Applications communicate in terms of data samples and multiple mappings from data to network packets are possible. As the packet layout and network type of Time Sensitive Networking differs substantially from traditional CAN frames, a new communication strategy must be developed. A one to one mapping between CAN frames and Ethernet frames would result in a lower transmission efficiency than CAN. For these reasons we propose a modelling a vehicle in terms of the data samples shared between the applications. Such a model can then be transformed into various network designs for experimentation using simulation.

\paragraph{Model generation}
Lightyear 0's embedded architecture consists of three main nodes developed by Lightyear, on which various control applications are deployed. The applications have been architected such that they communicate in terms of \textit{data dictionaries} and are agnostic of each other's deployment location and underlying communication network. This architecture makes it well suited for a transformation to TSN. The application's interface specifications provided most of the information necessary for creating a model describing the data sharing between applications. Crucially it lacked the consumption and production rate of the data dictionaries and the specific source and destination. The Lightyear's application software uses a well-defined interface in their source code for the creation and consumption of the data dictionaries. We have shown a method based on the call graph analysis performed on the full source code that is able to automatically retrieve the model's data. The resulting model is an overestimation of the actual data transferred. The call graph does not contain the context required to determine the conditions in which a call is made. As a result the method assumes that a data dictionary is read/written every cycle. A runnable could decide to subsample a data dictionary and the method would not be able to detect it. Accurately detecting those cases is very complex and even impossible as the condition could depend on run-time data. From inspecting the source code the number of overestimations seems limited. 

The same application software is also responsible for communication with third party nodes in the network. Communication with such nodes does not happen in terms of data dictionaries as these nodes have very specific protocols that must be implemented. Similarly to the data dictionaries, communication in terms of CAN messages occurs to a well-defined source code interface. The method names lacked the required information to automatically extract relevant information such as the CAN ID, message size or CAN bus. But we could automatically extract the locations in the source code where these communications take place. Recovering the data required considerable manual effort. Another drawback of our method is that it fails to detect a function calls using the C language function pointer syntax. This method is used in the \textit{safety supervisor core} runnable in the Safety Control Unit. As a result the number of CAN messages of this runnable is underestimated, and we did not get a full overview of the nodes communicating with the SCU. All these issues could be solved by implementing a similar communication strategy to the data dictionaries.

A drawback of the architecture is that the mapping of data dictionaries to CAN messages is not fixed and in fact is non-deterministic. During the build phase this mapping is created and thus change between software builds. Meaning all three programmable end nodes must be updated at the same time, but more importantly that the timing characteristics of the system will change. Additionally, changes in execution time of tasks transmitting CAN messages will also affect the timing characteristics of the CAN bus and thus the age of data used by runnables. One solution to mitigate the effects could be to use a defined mapping from data dictionaries to CAN messages. This reduces flexibility and the advantages of the architecture.

An additional benefit of the method is that the resulting model can be analysed, as seen in section~\ref{sec:benchmark}. Architects can use the generated model to compare the implementation with the requirements. Of particular note are the 162 data dictionaries that are produced but never consumed and vice versa. All these data dictionaries consume execution time on the controllers and time on the network for transmission. In some cases these are a result of partially implemented functionality, in some cases they are leftovers of refactored functionality, and sometimes they are a result of extra work implemented by developers which has no use. The relationship between the production and consumption rate of data dictionaries shows 56 data dictionaries which are consumed at a higher rate than they are produced, we cannot tell whether this is by design or design errors. It demonstrates that the generated model can also be used by architects to validate the implementation. The model generation method execution time is largely dependent on the speed of the compiler and linker, the call graph generation and analysis take a fraction of the time compared to compiling and linking the large code base. Additional benefits of this method are the ease of implementation as the complexity of call graph generation is already implemented by the freely available LLVM toolchain.

\paragraph{Sporadic and aperiodic data}
\todo{rewrite this section}
The benchmark focusses on the periodic CAN messages but in reality the vehicle also contains low priority debugging messages. For time reasons these streams where not benchmarked. The XCP, CCP and UDS protocols are used for diagnostics and firmware upgrades. These are protocols build on top of CAN, which are used to service vehicles in a garage or during testing of new software. The drawback of these protocols is that when active they change the behaviour of the CAN bus. A test of the system while a debugging stream is active is thus an invalid test as disabling the stream alters the timing of the system. Other drawbacks of these protocols is the overhead, a maximum size CAN frame already has 44 bits of overhead for every 64 bits of data in the best case before stuffing. The XCP, CCP and UDS protocols add extra headers in the data, reducing effective data transmission further. When considering a TSN based network this kind of traffic could either be mapped to best-effort traffic for non-time critical streams such as a software update. Or could be scheduled using the Credit Based Shaper for debugging data where a certain bandwidth is necessary, but the exact arrival times are not critical.

\paragraph{Transitioning to Time Sensitive Networking}
We have seen that the data dictionaries are generated and consumed at fixed rates. Making it suitable for transmission using the Time Aware Shaper in a TSN network. Usage of the Time Aware Shaper would remove the impact of runnables timing characteristics on the system by specifying a strict schedule. As a downside it reduces flexibility in the deployment of runnables. But since an Ethernet frame can contain 1500 bytes of payload all data dictionaries can be contained in just two Ethernet frames, one strategy could be to broadcast every data dictionary to every programmable end node at the maximum production rate. This would roughly equate to 208 kbit/second of payload data assuming a rate of 10 ms. Which is far lower than the 100 mbit/s available in Ethernet networks. An added benefit is the synchronization between all the system variables, removing bugs caused by communication delays. The ability to order the system's data using the globally accurate and synchronized time base provided by TSN greatly improves testing and debugging as well.

\paragraph{Execution model}
The model deviates from the implemented system as it assumes that runnables are scheduled by the real-time operating system. While in reality the runnables of a certain rate have been grouped together in one task that is scheduled. No reasoning could be found for the exact ordering of the runnables inside a task. Searching through the source control no evidence was found that the orderings where changed in order to optimize some performance. Our assumption is that they are somewhat arbitrary. The gap in documentation regarding scheduling led us to decide that the scheduler selects a random runnable from the available runnables for execution. In reality this process would likely be deterministic. But since the experiments are only a demonstration of the model's capabilities the influence on the results is not relevant. Similarly, no concrete data on the execution time of the tasks is retrieved. During the experiments we noted that the Vehicle Control Unit was overloaded, resulting in dropped CAN messages and a large spread in the age of data dictionary reads. This result should not be seen as proof of an issue in the real system. But we have seen that the Vehicle Control Unit receives a lot of CAN messages and that it may lead to spend a significant of time reading those messages. Which can be attributed to the event based nature of the receive task. Demonstrating that the model can be used to find bottlenecks in the system. Further analysis of a realistic ordering and execution times will improve the accuracy of the model without impacting the ability to answer relevant performance questions.

\paragraph{Simulation experiments}
The view of a system's state can vary in a decentralized system as data must be transmitted to the various nodes. This difference in system state is undesirable and can lead to issues such as controller instability. Our model records the difference in time between the generation of the sample and the time it is used. This metric can be used by system designers to determine whether the network performance supports the application requirements. We tried incorporating the age of input data dictionaries into the age of a data dictionary sample. The reason being that an old sample influences the calculations resulting in new samples of other data dictionaries. Unfortunately this was unsuccessful as no relationship between data dictionaries was defined in a structured way.

The work has mainly focussed in modelling a CAN based architecture and creating a simulation framework that can be used to evaluate the effects of network configuration on application performance. The automotive industry proposes a two-step transition from the traditional functional CAN based architecture to the zonal TSN based architecture. The first step introduces an TSN based backbone used by traditional domain based, or zonal controllers to communicate with each other. The domain based and zonal controllers act as a gateway between the TSN backbone and the legacy networks used to communicate with the controllers that still use CAN or LIN as their primary communication network. In the second step the controllers in a physical zone are consolidated into a single zonal ECU and a central controller is added resulting in the architecture depicted in figure~\ref{fig:zonal-arch}. We have seen that there are three major controllers in Lightyear's architecture. The application software already decouples the exchange of data between runnables from the transmission medium. A CAN receive and transmit runnable are automatically generated from the data dictionary interface description. A change to runnables receiving and transmitting TSN frames would be transparent to the runnables. A benefit would be that all three nodes can communicate directly with each other instead of the bridging required in the current architecture. But a decision must be made regarding the Vehicle and Powertrain CAN busses. In the current architecture they are used by several parametrizable end nodes as well as the programmable end nodes. If necessary the current CAN connection between programmable end nodes could be kept next to the Ethernet connection, allowing both nodes to communicate to the parametrizable end nodes. Or the busses are split up as to isolate the nodes into the required domains. Further investigation is necessary to determine the best course of action. The presented model accurately represents the software architecture of the programmable end nodes. The CAN receive and transmit runnables could be modified into TSN based runnables that use a TSN interface from the INET model suite. Which would be transparent for the other runnables and data dictionaries.

\todo{why is the result feasible and detailed enough}