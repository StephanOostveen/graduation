\section{Discussion}
\label{sec:discussion}
Traditional automotive benchmarks focused on the describing the network traffic in terms of messages transmitted between physical nodes. While interesting these benchmarks do not explain the reason behind the network traffic requirements. A network and its traffic are an implementation detail required to make the control application in a decentralized architecture work. Applications communicate in terms of data samples and multiple mappings from data to network packets are possible. As the packet layout and network type of Time Sensitive Networking differs substantially from traditional CAN frames, a new communication strategy must be developed. A one to one mapping between CAN frames and Ethernet frames would result in a lower transmission efficiency than CAN. For these reasons we propose modelling a vehicle in terms of the data samples shared between the applications. Such a model can then be transformed into various network designs for experimentation using simulation.

\subsection{Generating a model from source code}
Lightyear 0's embedded architecture consists of three main nodes developed by Lightyear, on which various control applications are deployed. The applications have been architected such that they communicate in terms of \textit{data dictionaries} and are agnostic of each other's deployment location and underlying communication network. This architecture makes it well suited for a transformation to TSN. The application's interface specifications provided most of the information necessary for creating a model describing the data sharing between applications. Crucially it lacked the consumption and production rate of the data dictionaries and the specific source and destination. The Lightyear's application software uses a well-defined interface in their source code for the creation and consumption of the data dictionaries. We have shown a method based on the call graph analysis performed on the full source code that is able to automatically retrieve the model's data. The resulting model is an overestimation of the actual data transferred. The call graph does not contain the context required to determine the conditions in which a call is made. As a result the method assumes that a data dictionary is read/written every cycle. A runnable could decide to subsample a data dictionary and the method would not be able to detect it. Accurately detecting those cases is very complex and even impossible as the condition could depend on run-time data. From inspecting the source code the number of overestimations seems limited. 

The same application software is also responsible for communication with third party nodes in the network. Communication with such nodes does not happen in terms of data dictionaries as these nodes have very specific protocols that must be implemented. Similarly to the data dictionaries, communication in terms of CAN messages occurs to a well-defined source code interface. The method names lacked the required information to automatically extract relevant information such as the CAN ID, message size or CAN bus. But we could automatically extract the locations in the source code where these communications take place. Recovering the data required considerable manual effort. Another drawback of our method is that it fails to detect a function calls using the C language function pointer syntax. This method is used in the \textit{safety supervisor core} runnable in the Safety Control Unit. As a result the number of CAN messages of this runnable is underestimated, and we did not get a full overview of the nodes communicating with the SCU. All these issues could be solved by implementing a similar communication strategy to the data dictionaries.

A drawback of the architecture is that the mapping of data dictionaries to CAN messages is not fixed and in fact is non-deterministic. During the build phase this mapping is created and thus change between software builds. Meaning all three programmable end nodes must be updated at the same time, but more importantly that the timing characteristics of the system will change. Additionally, changes in execution time of tasks transmitting CAN messages will also affect the timing characteristics of the CAN bus and thus the age of data used by runnables. One solution to mitigate the effects could be to use a defined mapping from data dictionaries to CAN messages. This reduces flexibility and the advantages of the architecture.

An additional benefit of the method is that the resulting model can be analysed, as seen in section~\ref{sec:benchmark}. Architects can use the generated model to compare the implementation with the requirements. Of particular note are the 162 data dictionaries that are produced but never consumed and vice versa. All these data dictionaries consume execution time on the controllers and time on the network for transmission. In some cases these are a result of partially implemented functionality, in some cases they are leftovers of refactored functionality, and sometimes they are a result of extra work implemented by developers which has no use. The relationship between the production and consumption rate of data dictionaries shows 56 data dictionaries which are consumed at a higher rate than they are produced, we cannot tell whether this is by design or design errors. It demonstrates that the generated model can also be used by architects to validate the implementation. The model generation method execution time is largely dependent on the speed of the compiler and linker, the call graph generation and analysis take a fraction of the time compared to compiling and linking the large code base. Additional benefits of this method are the ease of implementation as the complexity of call graph generation is already implemented by the freely available LLVM toolchain.

\paragraph{Sporadic and aperiodic data}
The benchmark focusses on the periodic CAN messages but in reality the vehicle also contains low priority debugging messages. For time reasons these streams where not benchmarked. The XCP, CCP and UDS protocols are used for diagnostics and firmware upgrades. These are protocols build on top of CAN, which are used to service vehicles in a garage or during testing of new software. The drawback of these protocols is that when active they change the behaviour of the CAN bus. A test of the system while a debugging stream is active is thus an invalid test as disabling the stream alters the timing of the system. Other drawbacks of these protocols is the overhead, a maximum size CAN frame already has 44 bits of overhead for every 64 bits of data in the best case before stuffing. The XCP, CCP and UDS protocols add extra headers in the data, reducing effective data transmission further. The motor inverters already have Ethernet based debugging interfaces and generate around 1 megabit of data per second, demonstrating that there is a need for higher bandwidth networks. A model for these extra data sources should be created such that they can be incorporated in a TSN network design.

\paragraph{Execution model}
The model deviates from the implemented system as it assumes that runnables are scheduled by the real-time operating system. While in reality the runnables of a certain rate have been grouped together in one task that is scheduled. No reasoning could be found for the exact ordering of the runnables inside a task. Searching through the source control no evidence was found that the orderings where changed in order to optimize some performance. Our assumption is that they are somewhat arbitrary. The gap in documentation regarding scheduling led us to decide that the scheduler selects a random runnable from the available runnables for execution. In reality this process would likely be deterministic. But since the experiments are only a demonstration of the model's capabilities the influence on the results is not relevant. Similarly, no concrete data on the execution time of the tasks is retrieved. Further analysis of a realistic ordering and execution times will improve the accuracy of the model without impacting the ability to answer relevant performance questions.

\paragraph{Transitioning to Time Sensitive Networking}
We have seen that the data dictionaries are generated and consumed at fixed rates. Making it suitable for transmission using the Time Aware Shaper in a TSN network. Usage of the Time Aware Shaper would remove the impact of runnables timing characteristics on the system by specifying a strict schedule. As a downside it reduces flexibility in the deployment of runnables. The bandwidth requirements of the three main nodes is relatively limited. Assuming every data dictionary is transmitted at the maximum rate of 10ms the required bandwidth roughly equates to 148 kbit/s, excluding protocol overhead. Which is far lower than the 100 mbit/s available in Ethernet networks. An added benefit is the synchronization between all the system variables, removing bugs caused by communication delays. The ability to order the system's data using the globally accurate and synchronized time base provided by TSN greatly improves testing and debugging as well. 

When considering a TSN based network the sporadic and aperiodic data streams could either be mapped to best-effort traffic for non-time critical streams such as software updates. Or could be scheduled using the Credit Based Shaper for debugging data where a certain bandwidth is necessary, but the exact arrival times are not critical. But as mentioned better understanding of the use cases and network requirements of those data streams should be created.

\subsection{Simulation experiments}
Looking at the performance of 200 simulations, we see that the model is capable of simulating 8 seconds per real second on five-year-old hardware. Demonstrating the feasibility of a vehicle level simulation on normal consumer hardware.

The simulation experiments are meant as a demonstration of the model's power, not as a thorough analysis of the system's performance. Looking at the results we have found that most of the nodes can operate as expected, demonstrated by a comparison between theoretical and simulated CAN bus bitrates. A discrepancy was found between the CAN busses that connect to the Vehicle Control Unit. We demonstrated that the simulation results can be used to find bottlenecks in the network caused by a node's schedule. Specifically the simulated Vehicle Control Unit is overloaded due to the numerous CAN messages that it receives and the chosen RTOS implementation. This simulated bottleneck could be caused by an overestimation in the received CAN messages by our model generation method. Alternatively the implementation of the CAN receive task could deviate from reality, but since the OpenECU documentation is not specific enough we cannot do better. Finally, the chosen execution times and orderings also have an effect on the node's load and as this data is missing it could deviate from reality. Nevertheless, this result demonstrates the model's capability of finding bottlenecks.

The view of a system's state can vary in a decentralized system as data must be transmitted to the various nodes. This difference in system state is undesirable and can lead to issues such as controller instability. Our model records the difference in time between the generation of the sample and the time it is used. An experiment was performed to demonstrate that the data dictionary age is not a scalar value, but rather a distribution that is dependent on network configuration. Data dictionary age can be used by system designers to determine whether the network performance supports the application requirements. We tried incorporating the age of input data dictionaries into the age of a data dictionary sample. The reason being that an old sample influences the calculations resulting in new samples of other data dictionaries. Unfortunately this was unsuccessful as no relationship between data dictionaries was defined in a structured way.

\paragraph{Transitioning to Time Sensitive Networking}
As mentioned earlier Lightyear 0's architecture decouples the transmission method between the programmable end nodes from the application's. Making it relatively easy to substitute the CAN based communication for a different network technology. Our \omnet model closely follows this architecture. Experiments with a TSN based network can be implemented relatively easily by using the INET Time Sensitive Networking models for the network and hardware interfaces. Some work is required to model the CAN receive and transmission runnables which transform the data dictionaries into network packets and vice versa. Further work should investigate a suitable mapping from data dictionaries to Ethernet frames, since Ethernet frames can contain a larger payload a new mapping will improve the system efficiency. The network topology of the powertrain and vehicle CAN bus should be redesigned as they not only serve the programmable end nodes but also various parametrizable end nodes.