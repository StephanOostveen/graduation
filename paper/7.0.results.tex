\section{Results}
\label{sec:results}
In section~\ref{sec:sota} we have seen benchmarks describing in-vehicle networks of several vehicles. Unfortunately these benchmarks were not suitable to create a model resembling the Lightyear 0's in-vehicle network. Section~\ref{sec:problem_statement} described that such a model is necessary for guiding the design of a new TSN based in-vehicle network. In section~\ref{sec:benchmark} we show the model representing the Lightyear 0's in-vehicle network, which was retrieved from the Lightyear 0's source code using the approach presented in ~\ref{subsec:model_gen}. The benchmark describes the datatypes, production/consumption pattern, rates and location of data dictionaries. The number of CAN messages and data data dictionaries produced and consumed is shown per runnable as well as the runnables period and priority. The network load of Ethernet based inverter interface is also described, demonstrating the need for network speeds that are unavailable in traditional automotive networks. Finally, a demonstration of the analyses possible with the presented model is presented in section~\ref{sec:experiments}. The results should be viewed as a demonstration that the extracted model is abstract enough to make simulation feasible, but is detailed enough to adequately answer performance questions at the system level.

\subsection{Lightyear 0's embedded system benchmark}
\label{sec:benchmark}

From a system's perspective communication happens mostly in terms of data dictionaries. They are the main mechanism for sharing the system state between runnables. Many solutions exist for transmitting the samples between physical nodes, but from the application's perspective it is not an important detail. In fact the mapping of data dictionaries to CAN messages is not fixed, but generated automatically during the build phase of the project and thus changes over time. In our benchmark we focus on describing the details of the data dictionaries as opposed to CAN messages. Table~\ref{tab:prog_nodes_types} shows the number of occurrences of a certain C-style datatype. This information was available in a single database and was trivially collectable.
\begin{table}[htb]
    \centering
    \begin{tabular}{@{}lll@{}}
    \toprule
    Type      & Size (bits) & Nr of data dictionaries \\ \midrule
    bool      & 8           & 25                     \\
    int8\_t   & 8           & 1                      \\
    uint8\_t  & 8           & 93                     \\
    int16\_t  & 16          & 88                     \\
    uint16\_t & 16          & 46                     \\
    int32\_t  & 32          & 19                     \\
    uint32\_t & 32          & 19                     \\
    float     & 32          & 144                    \\
    enumerate & 32          & 87                     \\ \bottomrule
    \end{tabular}
    \caption{Breakdown of data dictionary types used in the programmable end nodes}
    \label{tab:prog_nodes_types}
\end{table}

When deciding where in the network a certain data dictionary should be generated and which runnable should produce the samples it makes sense to take its usage pattern into account. Part of that pattern is how many runnables depend on the data dictionary. For example if only a single runnable depends on a data dictionary it might be more efficient from a network perspective to put these runnables on the same physical node, or even combine them into a single runnable. Table~\ref{tab:prog_nodes_read_write} shows the occurrence of a certain write/read ratio. For example, 303 data dictionaries are read by a single runnable, while only five data dictionaries are used by six or more runnables. Interestingly we found 27 data dictionaries which where read but never written and 135 data dictionaries that are written but never read. After investigating several of those cases and talking to developers it seems that these are either leftovers of code refactoring or functionality that is partially implemented. A developer working on runnable A might decide to proactively write a certain data dictionary so that a developer of runnable B can start using that data dictionary when necessary. A drawback of that approach is that time is wasted on creating and transmitting a data dictionary which has either no real data or is never used. The most used data dictionary is the \textit{vehicle\_speed}, which is used by 11 of the 46 runnables.
\begin{table}[htb]
    \centering
    \begin{tabular}{@{}llll@{}}
    \toprule
    \multicolumn{2}{c}{Nr of runnables} & & \\
    Writing & Reading & Occurences & Remarks\\ \midrule
    0                & 1                & 27         & \multirow{2}{*}{\begin{tabular}[c]{@{}l@{}}Partially implemented functionality,\\ leftovers from code refactoring\end{tabular}} \\
1                & 0                & 135        &                                                                                                                                 \\
1                & 1                & 303        & -                                                                                                                               \\
1                & 2                & 31         & -                                                                                                                               \\
1                & 3                & 11         & -                                                                                                                               \\
1                & 4                & 2          & -                                                                                                                               \\
1                & 6                & 1          & vehicle\_speed\_reliability                                                                                                     \\
1                & 8                & 1          & active\_gear                                                                                                                    \\
1                & 9                & 1          & operating\_mode\_ignition                                                                                                       \\
1                & 10               & 1          & power\_mode                                                                                                                     \\
1                & 11               & 1          & vehicle\_speed \\ \bottomrule
    \end{tabular}
    \caption{Read/write ratios for data dictionaries in the programmable end nodes}
    \label{tab:prog_nodes_read_write}
\end{table}

Part of the data dictionary usage pattern is the rate at which it is both produced and consumed. If a data dictionary is produced at a rate of 10ms but is only consumed every 500ms the data is potentially transmitted way more often than necessary, causing unnecessary network load. While the opposite could lead to an inconsistent view of the vehicle's state. Table~\ref{tab:data_dict_prod_cons_rates} shows the occurrence of a specific producer/consumer rate. It must be noted that some inaccuracies can exist as it is assumed that a data dictionary is read and written in every invocation of a runnable. While in reality the read and write action could be conditional, for example only every second iteration of a runnable. Unfortunately it is not feasible to extract this information using our method as that would entail parsing the entire C code in order to determine the conditions. Interesting are the cases on the bottom row and in the right column where a large difference in consumption and production rate occur. We did not investigate the reasons behind this discrepancy.
\begin{table}[htb]
    \centering
    \begin{tabular}{@{}lllllll@{}}\toprule
    & & \multicolumn{5}{c}{Consumer period (ms)}                                  \\\cmidrule{3-7}
    &  & 1 & 10 & 50  & 100 & 500 \\ \cmidrule{3-7}
    \multirow{5}{*}{\rotatebox[origin=c]{90}{\parbox{1.8cm}{Producer period (ms)}}} & 1      & 0 & 0  & 0   & 0   & 0   \\
                                & 10     & 0 & 58 & 76  & 0   & 17  \\
                                & 50     & 0 & 39 & 204 & 0   & 39  \\
                                & 100    & 0 & 0  & 0   & 0   & 0   \\
                                & 500    & 0 & 1  & 16  & 0   & 0  \\ \bottomrule
    \end{tabular}
    \caption{Number of data dictionaries produced and consumed at different runnable rates.}
    \label{tab:data_dict_prod_cons_rates}
\end{table}

Concluding the data dictionary usage pattern are the locations where a read or write occur. Which is interesting as this is the reason why a network is necessary in the first place. We identified three types of communication between runnables of the programmable end nodes: Local, Direct and Bridged, corresponding with figure~\ref{fig:one_physical}, \ref{fig:physical_example} and \ref{fig:bridging_example} respectively. Data dictionaries which are used by multiple runnables can have a combined communication type. Noteworthy are the cases where a data dictionary is only consumed on a different node than where it is produced. As a system designer this could be an opportunity for optimization, though it is likely that the production location is chosen for its physical location or the availability of certain hardware. The number of data dictionaries that are bridged is quite high, causing unnecessary load in the bridge. The possibility of adding a direct connection between the bridged node should be investigated.

\begin{table}[htb]
    \centering
    \begin{tabular}{@{}ll@{}}
    \toprule
    Communication type        & Count \\ \midrule
    Local only                & 140   \\
    Direct only               & 117   \\
    Bridged only              & 57    \\
    Local and direct          & 18    \\
    Local and bridged         & 6     \\
    Direct and bridged        & 6     \\
    Local, direct and bridged & 8     \\ \bottomrule
    \end{tabular}
    \caption{Breakdown of data dictionary read/write location}
    \label{tab:dd_rw_location}
\end{table}

A different perspective which is less relevant for the design of an in-vehicle network but is interesting for the design of the nodes, is the perspective of the runnables. Figure~\ref{fig:produce_consume_runnable} show for each runnable how many data dictionaries it consumes and produces. On the X and Y axis we see runnables that either do not consume or produce any data. Marked in orange are the runnables responsible for receiving or transmitting CAN messages to the other programmable end nodes. Some other big consumers and producers exist but the majority of the runnables produce and consume less than 20 data dictionaries. 
\begin{figure}[htb]
    \centering
    \input{images/Produce_Consume_graph.pgf}
    \caption{Data dictionaries consumed/produced per runnables}
    \label{fig:produce_consume_runnable}
\end{figure}

Going back to the network perspective, Figure~\ref{fig:produce_consume_CAN_runnable} shows the production and consumption of CAN messages broken down per runnable. Because parametrizable end nodes also communicate in terms of CAN messages they are also shown in the graph. Again on the X and Y axes we see in orange the runnables responsible for receiving and transmitting the data dictionaries as CAN messages. Responsible for 28 produced and 98 consumed CAN messages is the solar runnable on the VCU. The surrounding sense runnable is responsible for zero produced and 72 consumed messages, which also runs on the VCU. When all these messages are phased in the worst case, it could cause the Vehicle Control Unit to spend a lot of time scheduling and executing the CAN Sink application. If not taken into consideration this could lead to runnables missing their deadlines.
\begin{figure}[htb]
    \centering
    \input{images/Produce_Consume_CAN_graph.pgf}
    \caption{CAN messages consumed/produced per runnable or parametrizable node}
    \label{fig:produce_consume_CAN_runnable}
\end{figure}

As mentioned in section~\ref{subsec:network} due to time limitations only part of the Lightyear network was modelled. We also don't know how many nodes or CAN messages we did not model. Due to gaps in documentation this information needs to be retrieved from source code. Unfortunately our method does not work as expected on a specific part of the source code, this is limited to the \textit{safety supervisor core} runnable which executes on the Safety Control Unit. Table~\ref{tab:can_busses} summarizes the available information.

\begin{table}[htb]
    \centering
    \begin{tabular}{@{}llll@{}}
    \toprule
    Bus name          & Bitrate (kbps) & Nr of CAN messages & Nr of nodes \\ \midrule
    Driver support    & 125            & 4                  & 2           \\
    Drivetrain        & 500            & 18                 & 5           \\
    Energy management & 500            & 100                & 8           \\
    HVBS              & 500            & 13                 & 3           \\
    Powertrain        & 500            & 97                 & 7           \\
    Solar             & 500            & 153                & 15          \\
    Surrounding sense & 500            & 72                 & 9           \\
    Telematics        & 500            & 5                  & 2           \\
    Vehicle           & 500            & 64                 & 4           \\
    Vehicle 2         & 500            & 15                 & 5           \\ \bottomrule
    \end{tabular}
    \caption{Details of Lightyear 0's CAN busses}
    \label{tab:can_busses}
\end{table}

As mentioned in section~\ref{subsec:network} the four inverters each have a dedicated Ethernet network. In the default configuration these networks have only a single node connected to it: the inverter. Thus, there is no network traffic. When required a laptop can be connected to an inverter to form a two node network which can be used to configure or debug the inverter. The inverters implement an Internet Protocol stack using UDP to exchange messages. Configuration traffic is sparse, consisting of a dozen Ethernet frames exchanged between the two nodes. For debugging purposes the inverters sample seven 32-bit integers and 23 floating point numbers at 1 kHz which are streamed to debugging software on the laptop. This is good for 992 kilobit/second per inverter of measurement data. Assuming that one UDP datagram maps to one Ethernet frame and datagrams only contain full samples each inverter will send 1.05 megabit/second of Ethernet frames. 

Finally, tables~\ref{tab:runnable_mapping_cgw}, \ref{tab:runnable_mapping_scu} and \ref{tab:runnable_mapping_vcu} show the period and priority of each runnable. In the real deployments runnables with the same period deployed on a certain programmable end node have been grouped in a single task which is scheduled by the operating system, see Listing~\ref{lst:rtos_task} for an example. The runnables inside a task have been given a specific order in which they are executed. The reason for this deviation from the documented model or the reason for the specific order in which runnables are executed is unknown. The priorities are assigned in rate monotonic order, except for the tasks on the Central Gateway where the fastest task, \textit{cgw\_upgrade\_forwarding\_task} received the lowest priority. Which could be problematic as it is responsible for sending firmware updates to other nodes in the vehicle.

\lstinputlisting[caption=Example scheduled task, label={lst:rtos_task}, language=C, firstline=1,frame=single,numbers=left,keywordstyle=\color{blue}]{example_task.c}
\begin{table}[htb]
    \centering
\begin{tabular}{@{}llll@{}}
    \toprule
    Task                           & Period (ms) & Priority & Runnable                     \\ \midrule
    cgw\_task\_50ms                & 50          & 2        & Gateway receive              \\
                                   &             &          & Authentication manager       \\
                                   &             &          & Exterior lighting control    \\
                                   &             &          & Closures control             \\
                                   &             &          & Media ECU interface          \\
                                   &             &          & Vehicle Power Control        \\
                                   &             &          & Gateway transmit             \\
                                   &             &          & Version transmitter          \\
                                   &             &          & Non volatile memory manager  \\
    cgw\_task\_10ms                & 10          & 3        & Closures read button         \\
                                   &             &          & LIN task                     \\
    cgw\_upgrade\_forwarding\_task & 1           & 1        & Firmware upgrade forwarding  \\
    psc\_background\_app           & -           & 0        & -                            \\ \bottomrule
\end{tabular}
\caption{Mapping of runnables to scheduled task on the Central Gateway}
\label{tab:runnable_mapping_cgw}
\end{table}
\begin{table}[htb]
    \centering
\begin{tabular}{@{}llll@{}}
    \toprule
    Task                           & Period (ms) & Priority & Runnable                     \\ \midrule
    scu\_task\_10ms                & 10          & 4        & Safety supervisor controller \\
                                   &             &          & Energy controller            \\
                                   &             &          & Gear selector                \\
                                   &             &          & Airbags manager              \\
                                   &             &          & Steering angle interface     \\
                                   &             &          & Closures read button         \\
                                   &             &          & Propulsion control           \\
                                   &             &          & Propulsion safety            \\
    scu\_task\_50ms                & 50          & 2        & Gateway receive              \\
                                   &             &          & Vehicle power control        \\
                                   &             &          & Energy controller            \\
                                   &             &          & Driver controls              \\
                                   &             &          & Exterior lighting control    \\
                                   &             &          & Closures manager             \\
                                   &             &          & Braking system manager       \\
                                   &             &          & Gateway transmit             \\
                                   &             &          & Windows controller           \\
                                   &             &          & Power steering               \\
                                   &             &          & Version transmitter          \\
    psc\_background\_app           & -           & 0        & -                            \\ \bottomrule
\end{tabular}
\caption{Mapping of runnables to scheduled task on the Safety Control Unit}
\label{tab:runnable_mapping_scu}
\end{table}
\begin{table}[htb]
    \centering
\begin{tabular}{@{}llll@{}}
    \toprule
    Task                           & Period (ms) & Priority & Runnable                     \\ \midrule
    vcu\_task\_10ms                & 10          & 4        & Driver controls              \\
    vcu\_task\_50ms                & 50          & 3        & Gateway receive              \\
                                   &             &          & Driver controls              \\
                                   &             &          & Exterior lighting control    \\
                                   &             &          & Wiper manager                \\
                                   &             &          & Camera monitoring system     \\
                                   &             &          & Horn manager                 \\
                                   &             &          & Solar manager                \\
                                   &             &          & Power steering               \\
                                   &             &          & Vehicle power controller     \\
                                   &             &          & Acoustic Vehicle Alerting System \\
                                   &             &          & Gateway transmit             \\
                                   &             &          & Version transmitter          \\
    vcu\_task\_100ms               & 100         & 2        & Thermal management system    \\
    vcu\_task\_500ms               & 500         & 1        & Thermal management system    \\
    psc\_background\_app           & -           & 0        & -                            \\ \bottomrule
    \end{tabular}
    \caption{Mapping of runnables to scheduled task on the Vehicle Control Unit}
    \label{tab:runnable_mapping_vcu}
\end{table}

\clearpage
\subsection{Simulation experiments}
\label{sec:experiments}
In this section we demonstrate that the extracted model is abstract enough to make simulation feasible, but detailed enough to adequately answer performance questions at the system level. Analysis of the results' statistical significance is outside the scope of this project, it is likely that simulation parameters such as the task execution times will affect the network performance. But the chosen parameters might not accurately represent reality. 

\paragraph{A note on performance.} The experiments were executed on two machines with different hardware but similar software, the exact specifications are mentioned in the table below. To get a feeling for the simulation performance, 200 simulations were performed on both machines. The required time was recorded, the average simulation speed can be found in table~\ref{tab:performance} and contains all the overhead of setting up a simulation and storing the results. Each simulation used less than 100 megabytes of system memory and produced 1GB of data. These results should not be interpreted as an accurate statement of performance. They are simply stated to indicate achievable performance. We note a significant jump in performance in the multithreaded execution on the more modern desktop. We hypothesize that the modern desktop can achieve much higher clock speed in a multithreaded execution than the older laptop. While the clock speed difference in a single threaded workload does not differ that much between the machines.
\begin{table}[htb]
    \centering
    \begin{tabular}{@{}ll@{}}
    \toprule
    Laptop                                      & Desktop                                     \\ \midrule
    1.16 simulated seconds/second single thread & 1.48 simulated seconds/second single thread \\
    2.71 simulated seconds/second multi thread  & 8.05 simulated seconds/second multi thread  \\
    Lenovo T480                                 &                                             \\
    Intel i7-8550U (8 thread) 45W TDP CPU       & AMD Ryzen 5 3600 (12 thread) 65W TDP CPU    \\
    16 GB DDR4 @2400 MT/s memory                & 32 GB DDR4 @ 3200 MT/s memory               \\
    Fedora Linux 39, kernel 6.7.4               & Fedora Linux 39, kernel 6.7.4               \\
    Clang 17.0.6 compiler                       & Clang 17.0.6 compiler                       \\
    \omnet 6.0.2 framework                      & \omnet 6.0.2 framework                     \\ \bottomrule
    \end{tabular}
    \caption{Simulation performance}
    \label{tab:performance}
\end{table}

\paragraph{Selecting simulation parameters.}
We start by describing the simulation parameters that are not altered for the rest of the experiments. When evaluating the performance of the system these parameters must be chosen carefully as to reflect reality. In this study the model required any value to be able to execute here we state the chosen values for completeness together with the rationale.

The used CAN model (FiCo4OMNeT) implements the ability for a CAN frame to incur errors during its transmission, resulting in Error frames and the transmitting peripherals to retry the transmission. The error rate is an input parameter to the simulation and is used as the upperbound in a uniform distribution to determine whether a frame should become an error frame or not. In the following experiments an error rate of 0 is used, disabling error generation. The reason being that it complicates testing of the complete model and the lack of an accurate error model for the Lightyear 0. To reduce interference caused by specific execution times of runnables and the schedulers, the hardware buffer size of the programmable end nodes is set to 100 unless specifically mentioned. Real-time operating system task priorities have been assigned according to the OpenECU documentation which can be found in Section~\ref{subsec:programmablenode}. The runnables have been assigned the priorities as described in Table~\ref{tab:runnable_mapping_cgw},\ref{tab:runnable_mapping_scu} and \ref{tab:runnable_mapping_vcu}. 

In a real-time system a task's execution times directly influence the system's performance. Unfortunately no data on the runnables' execution times is unavailable, hence a method to fairly generate random execution times is used. We observed on several occasions that Lightyear had issues with programmable end nodes being overloaded. Assuming the runnables in the final product are schedulable, we will assume that the total ECU load is close to the scheduler's limit. The programmable end nodes use a fixed priority pre-emptive scheduler and the priorities are assigned rate monotonically. The Liu \& Layland least upper bound~\cite{liu1973scheduling} is used as the programmable end node utilization factor $U_{ECU}$. Since a total utilization less than or equal to this bound is always schedulable. Given $n$ tasks the utilization is given by:
\begin{equation}
    U_{ECU} = n \cdot (2^{1/n} -1)
\end{equation}

This fixed utilization is randomly distributed over the number of tasks running on that programmable end node using the Randfixedsum algorithm~\cite{emberson2010techniques}. The algorithm generates $n$ random numbers, lying in a given interval, whose sum is equal to $s$. As the node comprises a scheduling task, RTOS tasks and runnables, $U_{ECU}$ should be distributed over each task. As the lower bound for a task utilization we take 0.1\%, this could be a short task which only transmits a single CAN message with precomputed values. As the upper bound for a task utilization we take 50\%, since this occurred at Lightyear with one specific task. It is unlikely that the scheduler requires 50\% of the total utilization as this should be a highly optimized task. The same is true for the CAN receive and transmit tasks of the operating system. From analysing the source code we know that the background tasks are empty, so it can also receive a low utilization as to account for the context switching overhead. The assumed execution times, periods and resulting utilizations for the RTOS tasks are shown in table~\ref{tab:util}. The remaining utilization should be distributed over the $n$ runnables. And as mentioned previously each utilization $U_{task}$ should be in the range $0.001 < U < 0.5$.

\begin{table}[htb]
    \centering
    \begin{tabular}{@{}llll@{}}
    \toprule
    Task            & Execution time (ms) & Period (ms) & Utilization \\ \midrule
    Scheduler       & 0.001               & 1           & 0.001       \\
    CAN receive     & 0.1                 & 2           & 0.05        \\
    CAN transmit    & 0.01                & 2           & 0.005       \\
    Background task & 0.001               & 1           & 0.001       \\ \bottomrule
    \end{tabular}
    \caption{Real time operating system task utilization}
    \label{tab:util}
\end{table}

\paragraph{Comparing simulated CAN bitrates to theoretical bitrate.}

To validate that the simulation properly encodes and transmits all CAN messages the achieved bitrates and number of transmitted messages in the simulation are compared to the theoretical value. Because CAN uses bit stuffing in its encoding the FiCo4OMNeT framework added a configuration parameter for the percentage of bits that are stuffed. Because bit stuffing is dependent on the CAN ID and data transmitted the theoretical bitrate is a range. In the best case no bit stuffing occurs~\cite{davis2007controller}, the size in bits is found using formula~\ref{eq:min}. Where $g$ is 34 for standard format (11-bit identifiers) or 54 for extended format (29-bit identifiers), $n$ is the number of data $bytes$ in the payload.
\begin{equation}
    \label{eq:min}
    Framesize_{min}(n) = g+8\cdot n + 13
\end{equation}

The theoretical maximum bitrate~\cite{davis2007controller} is calculated using the maximum size formula~\ref{eq:max}. Where $g$ is 34 for standard format (11-bit identifiers) or 54 for extended format (29-bit identifiers), $n$ is the number of data $bytes$ in the payload.
\begin{equation}
    \label{eq:max}
Framesize_{max}(n) = g +8\cdot n +13 +\left\lfloor\frac{g+8\cdot n-1}{4}\right\rfloor
\end{equation}

Each CAN bus' theoretical minimum and maximum bitrate can be found in Table~\ref{tab:bitrate_sim}. We note that the theoretical maximal bitrates for the \textit{Energy management} and \textit{Surrounding sense} CAN buses are higher than the real world configured bitrates. This is likely due to an inaccuracy in the model generation method. For example, the method can not detect whether a runnable reads or transmits a CAN message on every iteration, every n'th iteration or aperiodically when a specific event occurs. From examination of source code, instances where found where a CAN message is transmitted every second iteration to achieve a lower transmission rate. Other instances where found where diagnostic messages where only transmitted during vehicle assembly, which would not occur during normal operation of the vehicle. Instead of manually removing these inaccuracies we increase the \textit{Energy management} and \textit{Surrounding sense} CAN bus bitrates to 1 megabit per second. Such that the remainder of this section can focus on showing the possibilities of the model when evaluating the full system's performance. Other interesting results are the bitrates of the \textit{Solar} and \textit{Powertrain} CAN buses. At 77\% and 67\% of the maximum bitrate respectively, scheduling issues are becoming more likely if the schedule is not chosen carefully.

We run two experiments on the entire vehicle network, varying the bit stuffing percentage as to achieve a minimal and maximal bitrate for each CAN bus. In the first experiment we set the bit stuffing percentage to 0, meaning no CAN message receives any stuffing bits. In the second experiment the bit stuffing percentage is set to 1, meaning that every CAN message receives the maximum number of stuffing bits. The runnables' execution times are drawn randomly using the Randfixedsum method described above, but are kept constant during this experiment. Each experiment is repeated 10 times and simulates 120 seconds with a warm-up period of 30 simulated seconds. The total number of bits transmitted on each CAN bus is recorded together with the number of transmitted frames. At the end the statistics are averages over the simulation length and taken as a single statistic for that repetition. For each experiment the average of the 10 repetitions is calculated and can be found under the simulation columns of table~\ref{tab:bitrate_sim}.

\begin{table}[htb]
    \centering
    \begin{tabular}{@{}lllllll@{}}
        \toprule
                                                                     & \multicolumn{3}{c}{Theoretical}                                                                                                                                                                     & \multicolumn{3}{c}{Simulated}                                                                                                                                                                     \\* \cmidrule(lr){2-4} \cmidrule(r){5-7}
        Bus name                                                     & \begin{tabular}[c]{@{}l@{}}Minimal \\ bitrate (bps)\end{tabular} & \begin{tabular}[c]{@{}l@{}}Maximal \\ bitrate (bps)\end{tabular} & \begin{tabular}[c]{@{}l@{}}Frames\\ per\\ second\end{tabular} & \begin{tabular}[c]{@{}l@{}}Minimal\\ bitrate (bps)\end{tabular} & \begin{tabular}[c]{@{}l@{}}Maximal\\ bitrate (bps)\end{tabular} & \begin{tabular}[c]{@{}l@{}}Frames\\ per\\ second\end{tabular} \\ \midrule
        Driver support                                               & 6,960                                                            & 8,400                                                            & 80                                                            & 4,900                                                           & 6,292                                                           & 58.14                                                         \\
        Drivetrain                                                   & 64,837                                                           & 78,856                                                           & 584                                                           & 64,842                                                          & 78,863                                                          & 584.16                                                        \\
        \begin{tabular}[c]{@{}l@{}}Energy \\ management\end{tabular} & 458,798                                                          & 558,925                                                          & 3,886                                                         & 458,828                                                         & 558,957                                                         & 3886.25                                                       \\
        HVBS                                                         & 47,553                                                           & 57,705                                                           & 463                                                           & 47,557                                                          & 57,709                                                          & 463.05                                                        \\
        Powertrain                                                   & 277,260                                                          & 337,500                                                          & 2,420                                                         & 277,280                                                         & 337,521                                                         & 2420.18                                                       \\
        Solar                                                        & 318,140                                                          & 386,200                                                          & 3,060                                                         & 298,483                                                         & 381,358                                                         & 2948.73                                                       \\
        \begin{tabular}[c]{@{}l@{}}Surrounding \\ sense\end{tabular} & 799,200                                                          & 972,000                                                          & 7,200                                                         & 799,218                                                         & 972,004                                                         & 7200.11                                                       \\
        Telematics                                                   & 27,593                                                           & 33,516                                                           & 260                                                           & 27,604                                                          & 33,530                                                          & 260.22                                                        \\
        Vehicle                                                      & 150,091                                                          & 183,226                                                          & 1,170                                                         & 139,227                                                         & 179,661                                                         & 1115.21                                                       \\
        Vehicle 2                                                    & 27,700                                                           & 33,500                                                           & 300                                                           & 25,488                                                          & 30,811                                                          & 280.10                                                        \\ \hline
        \end{tabular}
        \caption{Theoretical and simulated bitrates and frames per second per CAN bus}
        \label{tab:bitrate_sim}
\end{table}

\paragraph{Interference between task execution and achieved network performance}
As seen in the previous section the system as configured is not able to transmit the expected amount of messages. In this section we demonstrate that the simulation can be used to find the bottleneck of the \textit{Solar} and \textit{Driver support} CAN busses. The results should be interpreted as a demonstration of the feasibility of answering performance questions at the system level using the extracted model. Analysis of the results' statistical significance is outside the scope of this project, it is likely that the task execution times will affect the network performance. But in these experiments we have chosen a fixed set of execution times which might not accurately represent reality. Taking this into consideration we still run the experiments 100 times in order to demonstrate the feasibility of statistical analysis.

Table~\ref{tab:bitrate_sim} shows a large difference between the theoretical and simulated values for the \textit{Driver support}, \textit{Solar}, \textit{Vehicle} and \textit{Vehicle 2} buses. All except the \textit{Vehicle 2} are connected to the Vehicle Control Unit, making it likely that the Vehicle Control Unit is the bottleneck in those networks. If a runnable is rescheduled before the previous execution finished the runnable is said to be \textit{overrun}. When a runnable is overrun the model will not reschedule it until it has terminated, effectively skipping one or more iterations. As a result CAN messages will not be received or transmitted by the skipped occurrences. A schedulability problem in the Vehicle Control Unit would cause task overruns resulting in CAN frames not being transmitted, explaining the gap between the theoretical and simulated bitrates. The model tracks which task is being executed by the programmable end node. Figure~\ref{fig:task_util} shows the task utilization on the Vehicle Control Unit during the simulations. The Sink application dominates the VCU's utilization at 0.71, for that reason the x-axis of Figure~\ref{fig:task_util} is deliberately showing the range $[0; 0.05]$. As the Sink application is the highest priority task running on the system it will preempt the other tasks and extend their execution times that can lead into an overrun. 

\begin{figure}[htb]
    \centering
    \input{images/utilization.pgf}
    \caption{Utilization of tasks executing on the VCU for bit stuffing percentage 0}
    \label{fig:task_util}
\end{figure}

Two runnables on the Vehicle Control Unit transmit messages on the \textit{Solar} CAN bus, the \textit{Solar Controller} and \textit{Gateway Transmit} runnables. The \textit{Gateway Transmit} also transmits messages on the \textit{Vehicle} CAN bus while the \textit{Driver controls manager} runnable transmits on the \textit{Driver support} CAN bus. The model counts the total number of overruns during the simulation. Figure~\ref{fig:task_overrun} show the average number of overruns of the 100 repetitions and their 95\% confidence intervals. A rough calculation using the average number of overruns for the bit stuffing percentage 0 experiment, shows that the VCU fails to transmit 19,639 bits per second on the \textit{Solar} CAN bus. And 1990 bits per second for the \textit{Driver support} CAN bus, accounting for the missing bitrate. 

\begin{figure}[htb]
    \centering
    \input{images/task_overrun.pgf}
    \caption{Overruns of tasks executing on the VCU}
    \label{fig:task_overrun}
\end{figure}

\paragraph{Consistency of perceived vehicle state}
A data dictionary sample needs some amount of time to propagate from the producer to all its consumers. Let the time difference between the creation of a sample and the consumption of that sample be called the \textit{age} of the sample. If the consumers are local, the age is dictated by the execution order, running times and periods of the runnables on that node. In the case of non-local consumers one needs to take the communication delay and the schedule of both nodes into account. In this case the possibility exists that at a certain time, each node has a different view of the system's state. This difference in view is a direct consequence of the system level schedule. For designers, it might be important that the nodes have a consistent view of the system, that the maximum age stays below a predefined bound, or that the range is small. As we have seen in section~\ref{sec:benchmark}, specifically table~\ref{tab:dd_rw_location} $60\%$ of data dictionaries are consumed on other nodes than they were produced, making it likely that analysis of sample age is useful for guiding network configuration. As a concrete example showing the model's ability to analyse sample age figure~\ref{fig:vehicle_speed} shows the age of the \textit{vehicle speed} data dictionary throughout a single simulation run. The \textit{vehicle speed} data dictionary is chosen as it has the most consumers (11) and is consumed in all three programmable end nodes. Again these results should be interpreted in the context of the suitability to analyse system performance using the proposed model as opposed to a statistically sound analysis of the performance itself.

The \textit{vehicle speed} data dictionary is generated at a rate of 10 ms on the Safety control unit. Locally it is consumed at a rate of 10ms by two runnables, at a rate of 50 ms by two runnables of which one is the CAN transmit runnable. The Central Gateway has one runnable consuming the data dictionary at a rate of 10ms and 4 at a rate of 50ms. One of the 50ms runnables is the CAN transmit runnable which forwards the sample to the Vehicle Control Unit. The Vehicle Control Unit has two runnables consuming the \textit{vehicle speed} data dictionary at a rate of 50ms and one which consumes it at a 500ms rate. Looking at the age histogram of the Safety Control Unit in figure~\ref{fig:vehicle_speed} we see two peaks centred around 0 and 10 ms, consistent with the best and worst case scheduling of the runnables. In this simulation the Central Gateway's read age varies between 15 and 126 ms. Since the CAN receive and transmit tasks only run every 50ms such a large delay can be expected. Clearly visible in the Central Gateway histogram are the read peaks of the 10ms task as the \textit{vehicle speed} sample is only updated every 50ms. The Vehicle Control Unit has the largest spread in age, varying between 77 and 296ms. With two peaks centred around 150 and 200 ms, again this added delay is due to the CAN receive and transmit tasks having a period of 50ms. The Vehicle Control Unit histogram also has fewer counts, one reason being that the data dictionary is only sampled by two 50ms and one 500 ms runnables compared to the four 50ms and one 10ms runnables on the Central Gateway. A second explanation could be due to the overload condition of the Vehicle Control Unit previously mentioned.
\begin{figure}[htb]
    \centering
    \input{images/vehicle_speed_age.pgf}
    \caption{Age of the vehicle speed data dictionary in each programmable end node}
    \label{fig:vehicle_speed}
\end{figure}

\paragraph{Effect of hardware buffer size on the software buffer occupancy.} For the final experiment we show that the proposed model can be used to investigate the effects of microcontroller constraints on the software. Again these results should be seen as a feasibility experiment rather than a thorough analysis of the effect on performance of various microcontroller configurations. As mentioned earlier microcontrollers offering hardware CAN support often have one or more hardware buffers that buffer frames between the CAN bus and the application software. The number of buffers available varies greatly between microcontrollers. It can be as few as two on the NXP LPC1769 or as many as 96 on the NXP SPC5746, both are used during development of the Lightyear 0. As mentioned in section~\ref{subsec:network} the programmable end nodes have a software buffer in case the runnables request the transmission of a message while the hardware buffers are full. One question when developing the software buffer is how many CAN frames it must be able to hold, and whether the size of the available hardware buffer affects this. A second question could be how the size of the hardware buffer influences the transmission delay of the CAN messages. The model implements a variable size hardware buffer for the programmable end nodes such that these experiments can be performed. 

A series of experiments with varying hardware buffer sizes from the set ${2,10,16,48}$ was performed, each experiment is repeated 20 times. The model implements a software buffer for each CAN bus. Each buffer has one slot per CAN frame that the node transmits on that CAN bus. In case that a message with a certain CAN id is scheduled for transmission by a runnable, while that message still exists in the software buffer it will be overwritten. This behaviour is consistent with the OpenECU documentation. The size of each software buffer is logged throughout the simulation. In this experiment we look at the \textit{powertrain} buffer on the Safety Control Unit. Figure~\ref{fig:buffer_size} shows the probability to find a certain number of messages in the buffer for each of the simulated hardware buffer sizes.

For hardware buffer sizes 2 and 10 the software buffer always contain messages, indicating that the software is not able to transmit certain messages before they are overwritten by the runnables. This is obviously problematic since certain messages will never arrive at their destination. The OpenECU documentation states: \textquote{To lessen the load experienced by the CAN bus and the ECU, after the library has transmitted one message, it will wait for 2 milliseconds before determining the next message to transmit}. Our model implements this behaviour with the exception that it fills the hardware buffer completely before waiting for 2 milliseconds. Even with a hardware buffer size of 10 this behaviour results in messages which are never transmitted as the lowest recorded occupation still has two buffered messages. 
\begin{figure}[htb]
    \centering
    \input{images/buffersize.pgf}
    \caption{Software buffer occupation for various hardware buffer sizes}
    \label{fig:buffer_size}
\end{figure}